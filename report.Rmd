---
title: Impact of sitemaps on traffic to Italian Wikipedia from search engines
author: Mikhail Popov
date: "`r sub('^0(\\d)', '\\1', format(Sys.Date(), '%d %B %Y'))`"
abstract: |
  On 10 August 2018, the Wikimedia Performance Team deployed sitemaps for the Italian Wikipedia. We used Bayesian time series intervention analysis to answer the question of "Did the sitemaps have a positive effect on search engine-referred pageviews?"
output:
  wmfpar::pdf_report:
    short_title: Italian Wikipedia sitemap impact (T202643)
    watermark: "First Draft"
    cite_r_packages:
      # Presenation:
      - kableExtra
      # Data workflow:
      - magrittr
      - glue
      - dplyr
      - tidyr
      - purrr
      - broom
      - readr
      # Data visualization:
      - ggplot2
      - patchwork
      # Modeling
      - stats # arima()
      - rstan
      - bridgesampling
      # Misc.
      - wmf
    extra_bibs:
      - references.bib
    includes:
      after_body: appendix.tex
nocite: '@*'
---
```{r appendix, include=FALSE}
# Use the latest version of the appendix:
rmarkdown::render("appendix.Rmd", output_file = "appendix.tex", quiet = TRUE, envir = new.env())
```
```{r setup, include=FALSE}
library(knitr); library(kableExtra)
opts_chunk$set(
  echo = FALSE, message = FALSE, warning = FALSE,
  dev = "png", dpi = 600
)
options(knitr.table.format = "latex", scipen = 500, digits = 4)
library(ggplot2)
library(patchwork)
library(zeallot)
```

# Introduction

For a few days in July 2018, all traffic that went to the Italian Wikipedia was redirected (via JavaScript) to a [page protesting potential copyright changes in the European Union](https://it.wikipedia.org/wiki/Wikipedia:Comunicato_3_luglio_2018/en); refer to [Hershenov [-@hershenov_2018]](https://blog.wikimedia.org/2018/06/29/eu-copyright-proposal-will-hurt-web-wikipedia/) for more information. After the redirect ended, it was observed that there was still a non-negligible amount of traffic going to the redirect page (see [T199252](https://phabricator.wikimedia.org/T199252)), with almost a million pageviews on July 11th, a full six days after the redirect was turned off. In an attempt to fix the problem while also implementing a recommendation from our SEO consultation with Go Fish Digital ([T198965](https://phabricator.wikimedia.org/T198965)), the Wikimedia Performance team created [sitemaps](https://en.wikipedia.org/wiki/Sitemaps) for the Italian Wikipedia and deployed them on 10 August 2018.

In this report, we used Bayesian time series intervention analysis to determine whether the deployment of the sitemaps had a positive impact on search engine-referred traffic to the Italian Wikipedia, as measured by [pageviews](https://meta.wikimedia.org/wiki/Research:Page_view). Our statistical model of search engine-referred traffic employed an [autoregressive moving average model](https://en.wikipedia.org/wiki/Autoregressive%E2%80%93moving-average_model) for the time series with the change-due-to-intervention modeled as a gradually ramping-up, gradually levelling-off S-shaped curve -- which enabled us to infer the effect of sitemaps' deployment while:

- accounting for time it took search engines to ingest the sitemaps update their indices,[^1][^2][^3] and
- the reasonable assumption that there is an upper bound on how much additional traffic we can gain.

[^1]: "It will take some time before Google can process a sitemap that you have submitted [to Search Console]. Note that Google can't promise to crawl or index every URL in your sitemap because we rely complex algorithms to make crawling decisions." ([Source](https://support.google.com/webmasters/answer/183669))
[^2]: Note on sitemaps submitted in Bing Webmaster Tools: "processing submitted sitemaps takes time and can take from a few hours up to a few days." ([Source](https://www.bing.com/webmaster/help/how-to-submit-sitemaps-82a15bd4))
[^3]: Note sitemaps submitted in Yandex.Webmaster service: "The file is put into the processing queue. The robot will download it within two weeks. Every added file, including the ones listed in the Sitemap index file, is handled by the robot separately." ([Source](https://yandex.com/support/webmaster/indexing-options/sitemap.html))

```{r data, include=FALSE}
source("data.R")
source("summarizing.R")
itwiki_pageviews <- itwiki_pvs %>%
  dplyr::select(-day) %>%
  tidyr::gather(access_method, pageviews, both, desktop, `mobile web`)
```

\clearpage

```{r datavis_ts, fig.height=6, fig.width=10, fig.cap="The negative trend of the slowly decreasing desktop traffic cancels out the positive trend of the slowly increasing mobile (web) traffic, with the overall search engine traffic around 8 million pageviews per day."}
p1 <- ggplot(
  dplyr::filter(itwiki_pageviews, access_method == "both"),
  aes(x = date, y = pageviews)
) +
  geom_line() +
  geom_vline(
    aes(xintercept = date), linetype = "dashed",
    data = dplyr::filter(events, event == "sitemap deployment")
  ) +
  scale_color_brewer(palette = "Set1") +
  scale_x_date(date_breaks = "6 months", date_minor_breaks = "1 month") +
  labs(
    x = "Date", y = "Pageviews (in millions)",
    title = "Search engine traffic to the Italian Wikipedia"
  ) +
  wmf::theme_min(14)
p2 <- ggplot(
  dplyr::filter(itwiki_pageviews, access_method != "both"),
  aes(x = date, y = pageviews, color = access_method)
) +
  geom_line() +
  geom_vline(
    aes(xintercept = date), linetype = "dashed",
    data = dplyr::filter(events, event == "sitemap deployment")
  ) +
  scale_color_brewer(palette = "Set1") +
  scale_x_date(date_breaks = "6 months", date_minor_breaks = "1 month") +
  labs(
    x = "Date", y = "Pageviews (in millions)", color = "Access method",
    title = "Search engine traffic to the Italian Wikipedia, by access method"
  ) +
  wmf::theme_min(14)
p1 + p2 + plot_layout(ncol = 1)
```

```{r dataviz_monthly_seasonality, fig.width=8, fig.height=4, fig.cap="Every year the Italian Wikipedia has a similar pattern of search engine traffic across months, which indicated to us that months should be included in the model."}
ggplot(
  dplyr::filter(itwiki_pageviews, access_method == "both", date < "2018-09-01"),
  aes(x = month, y = pageviews, group = year, color = year)
) +
  stat_summary(fun.y = sum, geom = "line", size = 1.1) +
  scale_color_brewer(palette = "Set2") +
  labs(
    x = "Month", y = "Pageviews (in millions)", color = "Year",
    title = "Search engine traffic to the Italian Wikipedia, by year/month"
  ) +
  wmf::theme_min(14)
```

```{r dataviz_google}
ggplot(google_traffic, aes(x = date, y = pageviews)) +
  geom_line() +
  geom_vline(
    aes(xintercept = date), linetype = "dashed",
    data = dplyr::filter(events, event == "GSC submission")
  )
```

\clearpage

# Methods

```{r methods, child="methods.Rmd"}
```

# Results

```{r results, child="results.Rmd"}
```

# References

\footnotesize
